{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0519d8fd",
   "metadata": {},
   "source": [
    "# ML Iris - Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b154c82e",
   "metadata": {},
   "source": [
    "### Install missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81946442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.20.3\n",
      "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.24.2 pandas-1.5.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53641f",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb311f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6423ce8",
   "metadata": {},
   "source": [
    "### Create Spark & SQL context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a287eded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/14 13:28:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc =SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94da9a22",
   "metadata": {},
   "source": [
    "### Load Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7314a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"data\"\n",
    "file = os.path.join(data_dir,\"iris.csv\")\n",
    "panda_df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba233f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/conversion.py:327: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- variety: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df=sqlContext.createDataFrame(panda_df)\n",
    "iris_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f88bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- variety: string (nullable = true)\n",
      " |-- ind_variety: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(variety='Virginica', ind_variety=2.0),\n",
       " Row(variety='Versicolor', ind_variety=1.0),\n",
       " Row(variety='Setosa', ind_variety=0.0)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, StandardScaler, OneHotEncoder\n",
    "stringIndexer = StringIndexer(inputCol=\"variety\", outputCol=\"ind_variety\")\n",
    "si_model = stringIndexer.fit(iris_df)\n",
    "irisNormDf = si_model.transform(iris_df)\n",
    "irisNormDf.printSchema()\n",
    "irisNormDf.select(\"variety\",\"ind_variety\").distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8317521",
   "metadata": {},
   "source": [
    "### Perform Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5e09ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|summary|      sepal_length|       sepal_width|      petal_length|       petal_width|  variety|       ind_variety|\n",
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|  count|               150|               150|               150|               150|      150|               150|\n",
      "|   mean| 5.843333333333334|3.0573333333333323|3.7579999999999996|1.1993333333333336|     null|               1.0|\n",
      "| stddev|0.8280661279778636|0.4358662849366982| 1.765298233259466|0.7622376689603465|     null|0.8192319205190406|\n",
      "|    min|               4.3|               2.0|               1.0|               0.1|   Setosa|               0.0|\n",
      "|    max|               7.9|               4.4|               6.9|               2.5|Virginica|               2.0|\n",
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisNormDf.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba007486",
   "metadata": {},
   "source": [
    "### Prepare data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18875e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "def transformToLabeledPoint(row) :\n",
    "    lp = ( row[\"variety\"], row[\"ind_variety\"], \\\n",
    "                Vectors.dense([row[\"sepal_length\"],\\\n",
    "                        row[\"sepal_width\"], \\\n",
    "                        row[\"petal_length\"], \\\n",
    "                        row[\"petal_width\"]]))\n",
    "    return lp\n",
    "\n",
    "irisLp = irisNormDf.rdd.map(transformToLabeledPoint)\n",
    "irisLpDf = sqlContext.createDataFrame(irisLp,[\"species\",\"label\", \"features\"])\n",
    "\n",
    "scaler = StandardScaler(withMean=True, inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(irisLpDf)\n",
    "irisLpDf_scaled = scaler_model.transform(irisLpDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "049c3609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------------------+\n",
      "|species|label|      scaledFeatures|\n",
      "+-------+-----+--------------------+\n",
      "| Setosa|  0.0|[-0.8976738791967...|\n",
      "| Setosa|  0.0|[-1.1392004834649...|\n",
      "| Setosa|  0.0|[-1.3807270877331...|\n",
      "| Setosa|  0.0|[-1.5014903898672...|\n",
      "| Setosa|  0.0|[-1.0184371813308...|\n",
      "| Setosa|  0.0|[-0.5353839727944...|\n",
      "| Setosa|  0.0|[-1.5014903898672...|\n",
      "| Setosa|  0.0|[-1.0184371813308...|\n",
      "| Setosa|  0.0|[-1.7430169941354...|\n",
      "| Setosa|  0.0|[-1.1392004834649...|\n",
      "| Setosa|  0.0|[-0.5353839727944...|\n",
      "| Setosa|  0.0|[-1.2599637855990...|\n",
      "| Setosa|  0.0|[-1.2599637855990...|\n",
      "| Setosa|  0.0|[-1.8637802962695...|\n",
      "| Setosa|  0.0|[-0.0523307642581...|\n",
      "| Setosa|  0.0|[-0.1730940663921...|\n",
      "| Setosa|  0.0|[-0.5353839727944...|\n",
      "| Setosa|  0.0|[-0.8976738791967...|\n",
      "| Setosa|  0.0|[-0.1730940663921...|\n",
      "| Setosa|  0.0|[-0.8976738791967...|\n",
      "+-------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[species: string, label: double, scaledFeatures: vector]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisLpDf_scaled = irisLpDf_scaled.drop(\"features\")\n",
    "irisLpDf_scaled.show()\n",
    "irisLpDf_scaled.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb627086",
   "metadata": {},
   "source": [
    "### Perform Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2989ee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(species='Setosa', label=0.0, scaledFeatures=DenseVector([-1.26, 0.7862, -1.2225, -1.3111])),\n",
       " Row(species='Setosa', label=0.0, scaledFeatures=DenseVector([-0.5354, 1.9333, -1.3924, -1.0487])),\n",
       " Row(species='Versicolor', label=1.0, scaledFeatures=DenseVector([0.793, -0.5904, 0.477, 0.3945])),\n",
       " Row(species='Versicolor', label=1.0, scaledFeatures=DenseVector([-1.1392, -1.5081, -0.2594, -0.2615])),\n",
       " Row(species='Versicolor', label=1.0, scaledFeatures=DenseVector([0.0684, 0.3273, 0.5903, 0.788])),\n",
       " Row(species='Versicolor', label=1.0, scaledFeatures=DenseVector([0.6722, -0.361, 0.307, 0.1321])),\n",
       " Row(species='Versicolor', label=1.0, scaledFeatures=DenseVector([-0.5354, -0.1315, 0.4203, 0.3945])),\n",
       " Row(species='Virginica', label=2.0, scaledFeatures=DenseVector([0.793, -0.1315, 0.8169, 1.0504]))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split into training and testing data\n",
    "(trainingData, testData) = irisLpDf_scaled.randomSplit([0.8, 0.2])\n",
    "trainingData.count()\n",
    "testData.count()\n",
    "testData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e001b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e4debec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "dtClassifer = DecisionTreeClassifier(maxDepth=4, labelCol=\"label\",\\\n",
    "                featuresCol=\"scaledFeatures\")\n",
    "dtModel = dtClassifer.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "rdClassifier = RandomForestClassifier(labelCol=\"label\",\n",
    "                                      featuresCol=\"scaledFeatures\", numTrees=10)\n",
    "rdModel = rdClassifier.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "54846f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTreeClassifier': DecisionTreeClassificationModel: uid=DecisionTreeClassifier_32315f125cd5, depth=4, numNodes=11, numClasses=3, numFeatures=4,\n",
       " 'RandomForestClassifier': RandomForestClassificationModel: uid=RandomForestClassifier_2e01cbd75688, numTrees=10, numClasses=3, numFeatures=4}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'DecisionTreeClassifier': dtModel, 'RandomForestClassifier': rdModel}\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f355b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the test data\n",
    "predictions = [ models[list(models)[i]].transform(testData) for i in range(len(models)) ]\n",
    "# predictions.select(\"prediction\",\"species\",\"label\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40968709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTreeClassifier': 0.75, 'RandomForestClassifier': 0.875}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
    "                    labelCol=\"label\",metricName=\"accuracy\")\n",
    "evaluators = [ evaluator.evaluate(prediction) for prediction in predictions ]\n",
    "accuracies = dict()\n",
    "for i in range(len(list(models))):\n",
    "    accuracies[list(models)[i]] = evaluators[i]\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bed614",
   "metadata": {},
   "source": [
    "### Gradient Boosted Tree Classifier: One vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e9f985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoder\n",
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"label\", outputCol=\"label_vec\").fit(irisLpDf_scaled)\n",
    "irisLpDf_encoded = encoder.transform(irisLpDf_scaled)\n",
    "irisLpDf_encoded = irisLpDf_encoded.select('*', vector_to_array('label_vec').alias('label_col'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29233789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+---------+\n",
      "|      scaledFeatures|Setosa|Versicolor|Virginica|\n",
      "+--------------------+------+----------+---------+\n",
      "|[-0.8976738791967...|   1.0|       0.0|      0.0|\n",
      "|[-1.1392004834649...|   1.0|       0.0|      0.0|\n",
      "|[-1.3807270877331...|   1.0|       0.0|      0.0|\n",
      "|[-1.5014903898672...|   1.0|       0.0|      0.0|\n",
      "|[-1.0184371813308...|   1.0|       0.0|      0.0|\n",
      "|[-0.5353839727944...|   1.0|       0.0|      0.0|\n",
      "|[-1.5014903898672...|   1.0|       0.0|      0.0|\n",
      "|[-1.0184371813308...|   1.0|       0.0|      0.0|\n",
      "|[-1.7430169941354...|   1.0|       0.0|      0.0|\n",
      "|[-1.1392004834649...|   1.0|       0.0|      0.0|\n",
      "|[-0.5353839727944...|   1.0|       0.0|      0.0|\n",
      "|[-1.2599637855990...|   1.0|       0.0|      0.0|\n",
      "|[-1.2599637855990...|   1.0|       0.0|      0.0|\n",
      "|[-1.8637802962695...|   1.0|       0.0|      0.0|\n",
      "|[-0.0523307642581...|   1.0|       0.0|      0.0|\n",
      "|[-0.1730940663921...|   1.0|       0.0|      0.0|\n",
      "|[-0.5353839727944...|   1.0|       0.0|      0.0|\n",
      "|[-0.8976738791967...|   1.0|       0.0|      0.0|\n",
      "|[-0.1730940663921...|   1.0|       0.0|      0.0|\n",
      "|[-0.8976738791967...|   1.0|       0.0|      0.0|\n",
      "+--------------------+------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Binary Classification\n",
    "num_categories = len(irisLpDf_encoded.first()['label_col']) \n",
    "cols_expanded = [(col('label_col')[i].alias(f'{si_model.labels[i]}')) for i in range(num_categories)]\n",
    "irisLpDf_encoded = irisLpDf_encoded.select('scaledFeatures',*cols_expanded)\n",
    "irisLpDf_encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17c9f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Setosa', 'Versicolor', 'Virginica']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisLpDf_binary_class = {'Setosa': irisLpDf_encoded.select('scaledFeatures','Setosa'),\n",
    "                         'Versicolor': irisLpDf_encoded.select('scaledFeatures','Versicolor'),\n",
    "                         'Virginica': irisLpDf_encoded.select('scaledFeatures','Virginica')}\n",
    "list(irisLpDf_binary_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9a63ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setosa  - Accuracy: 1.0\n",
      "Versicolor  - Accuracy: 0.918918918918919\n",
      "Virginica  - Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "for i in range(len(list(irisLpDf_binary_class))):\n",
    "    #Split into training and testing data\n",
    "    (trainingData, testData) = irisLpDf_binary_class[list(irisLpDf_binary_class)[i]].randomSplit([0.8, 0.2])\n",
    "    trainingData.count()\n",
    "    testData.count()\n",
    "    testData.collect()\n",
    "    \n",
    "    gbClassifier = GBTClassifier(labelCol = list(irisLpDf_binary_class)[i], featuresCol = 'scaledFeatures')\n",
    "    gbModel = gbClassifier.fit(trainingData)\n",
    "    predictions = gbModel.transform(testData)\n",
    "    \n",
    "    #Evaluate accuracy\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(labelCol = list(irisLpDf_binary_class)[i], metricName = 'accuracy')\n",
    "    print(list(irisLpDf_binary_class)[i], ' - Accuracy:', multi_evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c322b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
